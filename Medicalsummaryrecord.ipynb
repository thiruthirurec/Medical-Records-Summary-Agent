{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qUSWevf-q87B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai==0.6.0 in ./.venv/lib/python3.14/site-packages (0.6.0)\n",
      "Collecting google-ai-generativelanguage==0.6.4 (from google-generativeai==0.6.0)\n",
      "  Using cached google_ai_generativelanguage-0.6.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-api-core in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.25.2)\n",
      "Requirement already satisfied: google-api-python-client in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.43.0)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (4.25.3)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.12.5)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai==0.6.0) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.14/site-packages (from google-api-core->google-generativeai==0.6.0) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.14/site-packages (from google-api-core->google-generativeai==0.6.0) (2.32.5)\n",
      "Collecting google-ai-generativelanguage==0.6.4 (from google-generativeai==0.6.0)\n",
      "  Using cached google_ai_generativelanguage-0.6.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-api-core in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.25.2)\n",
      "Requirement already satisfied: google-api-python-client in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.43.0)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (4.25.3)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (2.12.5)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.14/site-packages (from google-generativeai==0.6.0) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai==0.6.0) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.14/site-packages (from google-api-core->google-generativeai==0.6.0) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./.venv/lib/python3.14/site-packages (from google-api-core->google-generativeai==0.6.0) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai==0.6.0) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai==0.6.0) (1.62.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.14/site-packages (from google-auth>=2.15.0->google-generativeai==0.6.0) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.14/site-packages (from google-auth>=2.15.0->google-generativeai==0.6.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.14/site-packages (from google-auth>=2.15.0->google-generativeai==0.6.0) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.14/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai==0.6.0) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./.venv/lib/python3.14/site-packages (from google-api-python-client->google-generativeai==0.6.0) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.14/site-packages (from google-api-python-client->google-generativeai==0.6.0) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.14/site-packages (from google-api-python-client->google-generativeai==0.6.0) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in ./.venv/lib/python3.14/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai==0.6.0) (3.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.14/site-packages (from pydantic->google-generativeai==0.6.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.14/site-packages (from pydantic->google-generativeai==0.6.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.14/site-packages (from pydantic->google-generativeai==0.6.0) (0.4.2)\n",
      "Using cached google_ai_generativelanguage-0.6.4-py3-none-any.whl (679 kB)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai==0.6.0) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai==0.6.0) (1.62.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.14/site-packages (from google-auth>=2.15.0->google-generativeai==0.6.0) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.14/site-packages (from google-auth>=2.15.0->google-generativeai==0.6.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.14/site-packages (from google-auth>=2.15.0->google-generativeai==0.6.0) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.14/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.6.0) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.14/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai==0.6.0) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./.venv/lib/python3.14/site-packages (from google-api-python-client->google-generativeai==0.6.0) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.14/site-packages (from google-api-python-client->google-generativeai==0.6.0) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.14/site-packages (from google-api-python-client->google-generativeai==0.6.0) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in ./.venv/lib/python3.14/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai==0.6.0) (3.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.14/site-packages (from pydantic->google-generativeai==0.6.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.14/site-packages (from pydantic->google-generativeai==0.6.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.14/site-packages (from pydantic->google-generativeai==0.6.0) (0.4.2)\n",
      "Using cached google_ai_generativelanguage-0.6.4-py3-none-any.whl (679 kB)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.9.0\n",
      "    Uninstalling google-ai-generativelanguage-0.9.0:\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.9.0\n",
      "    Uninstalling google-ai-generativelanguage-0.9.0:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.9.0\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 3.2.0 requires google-ai-generativelanguage<1.0.0,>=0.9.0, but you have google-ai-generativelanguage 0.6.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 3.2.0 requires google-ai-generativelanguage<1.0.0,>=0.9.0, but you have google-ai-generativelanguage 0.6.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.4\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.14/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.14/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-google-genai in ./.venv/lib/python3.14/site-packages (3.2.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in ./.venv/lib/python3.14/site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in ./.venv/lib/python3.14/site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.14/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.3.45)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.14/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.14/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-google-genai in ./.venv/lib/python3.14/site-packages (3.2.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in ./.venv/lib/python3.14/site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in ./.venv/lib/python3.14/site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.14/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.3.45)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.14/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.14/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.14/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.14/site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./.venv/lib/python3.14/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.venv/lib/python3.14/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.14/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.14/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.14/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.14/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.14/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.14/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.14/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.14/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.14/site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./.venv/lib/python3.14/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.venv/lib/python3.14/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.14/site-packages (from langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.14/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.14/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.14/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.14/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.14/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.14/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.14/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.14/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.14/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.25.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.43.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.25.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.14/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.14/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.14/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.14/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.14/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.25.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.43.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in ./.venv/lib/python3.14/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.25.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.14/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.14/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.14/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.14/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.14/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.14/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.14/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.14/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
      "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
      "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.6.0 requires google-ai-generativelanguage==0.6.4, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.6.0 requires google-ai-generativelanguage==0.6.4, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.9.0\n",
      "Requirement already satisfied: PyMuPDF in ./.venv/lib/python3.14/site-packages (1.26.6)\n",
      "Requirement already satisfied: pytesseract in ./.venv/lib/python3.14/site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.14/site-packages (12.0.0)\n",
      "Requirement already satisfied: packaging>=21.3 in ./.venv/lib/python3.14/site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: PyMuPDF in ./.venv/lib/python3.14/site-packages (1.26.6)\n",
      "Requirement already satisfied: pytesseract in ./.venv/lib/python3.14/site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.14/site-packages (12.0.0)\n",
      "Requirement already satisfied: packaging>=21.3 in ./.venv/lib/python3.14/site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.14/site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./.venv/lib/python3.14/site-packages (from faiss-cpu) (2.3.5)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.14/site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.14/site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./.venv/lib/python3.14/site-packages (from faiss-cpu) (2.3.5)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.14/site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.14/site-packages (1.0.4)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.14/site-packages (1.0.4)\n",
      "Requirement already satisfied: langgraph-prebuilt in ./.venv/lib/python3.14/site-packages (1.0.5)\n",
      "Requirement already satisfied: langgraph-prebuilt in ./.venv/lib/python3.14/site-packages (1.0.5)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./.venv/lib/python3.14/site-packages (from langgraph) (1.1.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.venv/lib/python3.14/site-packages (from langgraph) (2.1.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.14/site-packages (from langgraph) (0.2.10)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./.venv/lib/python3.14/site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.14/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.14/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.14/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.14/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.14/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.14/site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./.venv/lib/python3.14/site-packages (from langgraph) (1.1.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.venv/lib/python3.14/site-packages (from langgraph) (2.1.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.14/site-packages (from langgraph) (0.2.10)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./.venv/lib/python3.14/site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.14/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.14/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.14/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.14/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.14/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.14/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.14/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.14/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.14/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.14/site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.14/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.14/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.14/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.14/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.14/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Name: langgraph\n",
      "Version: 1.0.4\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: https://docs.langchain.com/oss/python/langgraph/overview\n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: /Users/thirumurugan/Documents/Folder/New Volume F/New Volume F/30_P_Project/Google/.venv/lib/python3.14/site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph-sdk, pydantic, xxhash\n",
      "Required-by: langchain\n",
      "---\n",
      "Name: langgraph-prebuilt\n",
      "Version: 1.0.5\n",
      "Summary: Library with high-level APIs for creating and executing LangGraph agents and tools.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: /Users/thirumurugan/Documents/Folder/New Volume F/New Volume F/30_P_Project/Google/.venv/lib/python3.14/site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint\n",
      "Required-by: langgraph\n",
      "Name: langgraph\n",
      "Version: 1.0.4\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: https://docs.langchain.com/oss/python/langgraph/overview\n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: /Users/thirumurugan/Documents/Folder/New Volume F/New Volume F/30_P_Project/Google/.venv/lib/python3.14/site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph-sdk, pydantic, xxhash\n",
      "Required-by: langchain\n",
      "---\n",
      "Name: langgraph-prebuilt\n",
      "Version: 1.0.5\n",
      "Summary: Library with high-level APIs for creating and executing LangGraph agents and tools.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: /Users/thirumurugan/Documents/Folder/New Volume F/New Volume F/30_P_Project/Google/.venv/lib/python3.14/site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint\n",
      "Required-by: langgraph\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai==0.6.0\n",
    "!pip install langchain langchain-community langchain-google-genai\n",
    "!pip install PyMuPDF pytesseract pillow\n",
    "# !apt-get install -y tesseract-ocr # Uncomment for Linux/Colab. For macOS use: brew install tesseract\n",
    "!pip install faiss-cpu\n",
    "!pip install --upgrade langgraph langgraph-prebuilt\n",
    "!pip show langgraph langgraph-prebuilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Hack to prevent protobuf from trying to load C extension which fails on Python 3.14\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "sys.modules[\"google._upb._message\"] = None\n",
    "\n",
    "from pathlib import Path\n",
    "import io, base64\n",
    "from typing import List\n",
    "import fitz  # PyMuPDF\n",
    "from pypdf import PdfReader          # read PDFs\n",
    "from PIL import Image                # image handling\n",
    "from langchain_core.documents import Document # Updated import\n",
    "from langchain_core.messages import HumanMessage # Updated import\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_community.vectorstores import FAISS # Updated import to FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from IPython.display import display, Image as IPImage\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import time\n",
    "from pathlib import Path\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c-CfCSjmrbZ8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "# Hack to prevent protobuf from trying to load C extension which fails on Python 3.14\n",
    "sys.modules[\"google._upb._message\"] = None\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBAvGtRsUdilx_NG69USx7XgQaYFli4Ms8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zYCYSvrlr3Oc"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBAvGtRsUdilx_NG69USx7XgQaYFli4Ms8\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to describe an image using gpt 4o mini\n",
    "def summarize_image(b64_img: str, max_words: int = 60) -> str:\n",
    "    prompt = (\n",
    "        f\"Describe this image in {max_words} words or fewer. \"\n",
    "        \"Focus on charts, tables, or numbers if present.\"\n",
    "    )\n",
    "    msg = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{b64_img}\"},\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return llm.invoke([msg]).content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing PDF \n",
      "Parsed 2 documents (text + image summaries).\n",
      "Parsed 2 documents (text + image summaries).\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "MAX_RETRIES = 3\n",
    "DELAY_BETWEEN_CALLS = 1.0  # seconds (adjust based on your tier)\n",
    "BATCH_SIZE = 3  # Summarize 3 images at a time (optional, advanced)\n",
    "\n",
    "# --- Main Loop ---\n",
    "docs_path = Path(\"/Users/thirumurugan/Documents/Folder/New Volume F/New Volume F/30_P_Project/Google/Data/medicalreport Results.pdf\")\n",
    "reader = PdfReader(docs_path)\n",
    "\n",
    "all_docs: List[Document] = []\n",
    "\n",
    "img_dir = Path(\"./tmp_images\")\n",
    "img_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Parsing PDF \")\n",
    "\n",
    "for page_num, page in enumerate(reader.pages):\n",
    "    # --------------------- Extract plain text --------------\n",
    "    plain_text = page.extract_text() or \"\"\n",
    "    if plain_text.strip():\n",
    "        all_docs.append(\n",
    "            Document(\n",
    "                page_content=plain_text,\n",
    "                metadata={\n",
    "                    \"source\": str(docs_path),\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"kind\": \"text\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # ------------------ Extract and summarize images -------------------\n",
    "    for img_idx, img_file in enumerate(page.images):\n",
    "        img = Image.open(io.BytesIO(img_file.data))\n",
    "        buffered = io.BytesIO()\n",
    "        img.save(buffered, format=\"PNG\")\n",
    "        b64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "        # Save image\n",
    "        img_path = img_dir / f\"page{page_num+1}_img{img_idx}.png\"\n",
    "        img.save(img_path)\n",
    "\n",
    "        # --- Retry logic with delay ---\n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            try:\n",
    "                summary = summarize_image(b64)\n",
    "                break  # Success  exit retry loop\n",
    "            except Exception as e:\n",
    "                if \"rate_limit\" in str(e).lower() or \"429\" in str(e):\n",
    "                    wait = DELAY_BETWEEN_CALLS * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"Rate limit hit. Retrying in {wait:.1f}s... (attempt {attempt + 1})\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    print(f\"Error summarizing image: {e}\")\n",
    "                    summary = \"[Image summary failed]\"\n",
    "                    break\n",
    "        else:\n",
    "            summary = \"[Image summary failed after retries]\"\n",
    "\n",
    "        # Append document\n",
    "        all_docs.append(\n",
    "            Document(\n",
    "                page_content=f\"Image on page {page_num + 1}: {summary}\",\n",
    "                metadata={\n",
    "                    \"source\": str(docs_path),\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"kind\": \"image_summary\",\n",
    "                    \"image_path\": str(img_path),\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Small delay between images\n",
    "        time.sleep(DELAY_BETWEEN_CALLS)\n",
    "\n",
    "print(f\"Parsed {len(all_docs)} documents (text + image summaries).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JWZpoWX9rhQc"
   },
   "outputs": [],
   "source": [
    "def extract_text_and_images_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text + OCR images from each page.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        # Extract text\n",
    "        text = page.get_text()\n",
    "        full_text += text + \"\\n\"\n",
    "\n",
    "        # Extract images\n",
    "        for img in page.get_images(full=True):\n",
    "            xref = img[0]\n",
    "            pix = fitz.Pixmap(doc, xref)\n",
    "\n",
    "            if pix.n < 5:\n",
    "                img_data = pix.tobytes(\"png\")\n",
    "            else:\n",
    "                pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "                img_data = pix.tobytes(\"png\")\n",
    "\n",
    "            # OCR on image\n",
    "            try:\n",
    "                pil_img = Image.open(io.BytesIO(img_data))\n",
    "                ocr_text = pytesseract.image_to_string(pil_img)\n",
    "                full_text += \"\\n\" + ocr_text\n",
    "            except Exception as e:\n",
    "                # Skip OCR if tesseract is not found or fails\n",
    "                print(f\"OCR failed for image on page {page.number}: {e}\")\n",
    "                pass\n",
    "\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split into 2 final chunks.\n"
     ]
    }
   ],
   "source": [
    "# Chunk the text (not the images)\n",
    "# We split only text pages, image summaries are already short.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,  # ~750 tokens worth of characters\n",
    "    chunk_overlap=400,  # ~100 tokens worth of characters\n",
    ")\n",
    "\n",
    "chunked_docs: List[Document] = []\n",
    "for doc in all_docs:\n",
    "    if doc.metadata[\"kind\"] == \"image_summary\":\n",
    "        # keep image summaries as-is\n",
    "        chunked_docs.append(doc)\n",
    "    else:\n",
    "        # split textual pages into smaller chunks\n",
    "        for chunk in text_splitter.split_documents([doc]):\n",
    "            chunked_docs.append(chunk)\n",
    "\n",
    "print(f\"Data Split into {len(chunked_docs)} final chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and Build a vector store using Gemini embeddings\n",
    "# Using FAISS for local vector storage\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "# vectorstore = FAISS.from_documents(\n",
    "#     documents=chunked_docs,\n",
    "#     embedding=embeddings\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "SWp980QnrlRO"
   },
   "outputs": [],
   "source": [
    "def index_pdf_directory(pdf_folder):\n",
    "    \"\"\"Index all PDFs in a folder.\"\"\"\n",
    "    all_chunks = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "    if not os.path.exists(pdf_folder):\n",
    "        os.makedirs(pdf_folder)\n",
    "        print(f\"Created folder: {pdf_folder}. Please add PDF files there.\")\n",
    "        return None\n",
    "\n",
    "    files = [f for f in os.listdir(pdf_folder) if f.lower().endswith(\".pdf\")]\n",
    "    if not files:\n",
    "        print(f\"No PDF files found in {pdf_folder}.\")\n",
    "        return None\n",
    "\n",
    "    for filename in files:\n",
    "        pdf_path = os.path.join(pdf_folder, filename)\n",
    "        text = extract_text_and_images_from_pdf(pdf_path)\n",
    "        \n",
    "        if not text.strip():\n",
    "            print(f\"Warning: No text extracted from {filename}. It might be an image-only PDF and OCR failed.\")\n",
    "            continue\n",
    "\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        for chunk in chunks:\n",
    "            all_chunks.append({\"text\": chunk, \"source\": filename})\n",
    "\n",
    "    if not all_chunks:\n",
    "        print(\"No text chunks found to index.\")\n",
    "        return None\n",
    "\n",
    "    texts = [c[\"text\"] for c in all_chunks]\n",
    "    metadatas = [{\"source\": c[\"source\"]} for c in all_chunks]\n",
    "\n",
    "    vectordb = FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bCNR4rfyrpJ7"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "classifier_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Classify this query into a medical record type:\n",
    "Options: lab_report, discharge_summary, radiology_report, prescription, consultation, operative_report, progress_note, any\n",
    "Query: {query}\n",
    "Answer ONLY with record type:\n",
    "\"\"\")\n",
    "\n",
    "# classifier_agent = LLMChain(llm=llm, prompt=classifier_prompt)\n",
    "classifier_agent = classifier_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0pJgwe6FrqxT"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "import json\n",
    "\n",
    "def search_pdf(query, record_type):\n",
    "    \"\"\"Search vector DB with optional record type filtering.\"\"\"\n",
    "    if vectordb is None:\n",
    "        return \"No documents indexed. Please add PDF files to the Data folder.\"\n",
    "        \n",
    "    docs = vectordb.similarity_search(query, k=10)\n",
    "    output = \"\"\n",
    "    for d in docs:\n",
    "        output += f\"[{d.metadata['source']}] {d.page_content}\\n\"\n",
    "    return output\n",
    "\n",
    "def search_pdf_wrapper(q):\n",
    "    try:\n",
    "        # If q is a string that looks like a dict, try to parse it\n",
    "        if isinstance(q, str) and \"{\" in q:\n",
    "             # Replace single quotes with double quotes for JSON compatibility if needed\n",
    "             q_fixed = q.replace(\"'\", '\"')\n",
    "             q_dict = json.loads(q_fixed)\n",
    "             return search_pdf(q_dict.get(\"query\", q), q_dict.get(\"record_type\", \"any\"))\n",
    "        elif isinstance(q, dict):\n",
    "             return search_pdf(q.get(\"query\", \"\"), q.get(\"record_type\", \"any\"))\n",
    "        else:\n",
    "             return search_pdf(str(q), \"any\")\n",
    "    except Exception as e:\n",
    "        return search_pdf(str(q), \"any\")\n",
    "\n",
    "pdf_search_tool = Tool(\n",
    "    name=\"medical_pdf_search\",\n",
    "    func=search_pdf_wrapper,\n",
    "    description=\"Search medical PDFs with vector index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1kezAEKvrscV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/myhfchxs55d9032jyvb4tzb00000gn/T/ipykernel_26943/1675910413.py:8: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  retrieval_executor = create_react_agent(llm, [pdf_search_tool])\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# retrieval_executor = create_react_agent(llm, [pdf_search_tool])\n",
    "# Note: LangGraph's create_react_agent uses tool calling.\n",
    "# If Gemini doesn't support tool calling well with this setup, we might need a different approach.\n",
    "# But Gemini 1.5 Pro should support it.\n",
    "\n",
    "retrieval_executor = create_react_agent(llm, [pdf_search_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success importing create_react_agent\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import langgraph\n",
    "import langgraph.prebuilt\n",
    "importlib.reload(langgraph)\n",
    "importlib.reload(langgraph.prebuilt)\n",
    "try:\n",
    "    from langgraph.prebuilt import create_react_agent\n",
    "    print(\"Success importing create_react_agent\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3g8QMUpWruLz"
   },
   "outputs": [],
   "source": [
    "summariser_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Summarise the following medical text clearly and clinically:\n",
    "{snippets}\n",
    "\"\"\")\n",
    "\n",
    "# summariser_agent = LLMChain(llm=llm, prompt=summariser_prompt)\n",
    "summariser_agent = summariser_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "p8nCO_LLsBbU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Supervisor Agent Compiled Successfully.\n"
     ]
    }
   ],
   "source": [
    "timeline_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Create a chronological medical timeline from:\n",
    "{snippets}\n",
    "\n",
    "Format:\n",
    "- Date (or Unknown)\n",
    "- Event Description\n",
    "- Summary of medical event\n",
    "- What happened\n",
    "\"\"\")\n",
    "\n",
    "# timeline_agent = LLMChain(llm=llm, prompt=timeline_prompt)\n",
    "timeline_agent = timeline_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ==========================================\n",
    "#  ADVANCED PIPELINE: TOOLS & SUPERVISOR\n",
    "# ==========================================\n",
    "\n",
    "# 1. Define Structured Tools (The Workers)\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from typing import List, Optional, TypedDict\n",
    "from datetime import datetime\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Schema for structured output\n",
    "class MedicalEvent(BaseModel):\n",
    "    date: str = Field(description=\"Date of the event in YYYY-MM-DD format. Use 'Unknown' if not found.\")\n",
    "    event_type: str = Field(description=\"Type: Admission, Diagnosis, Lab, Surgery, Discharge, Imaging, etc.\")\n",
    "    description: str = Field(description=\"Clinical summary of the event.\")\n",
    "    details: str = Field(description=\"Specific values, results, or medication details.\")\n",
    "\n",
    "class MedicalTimeline(BaseModel):\n",
    "    events: List[MedicalEvent]\n",
    "\n",
    "# Parser\n",
    "parser = JsonOutputParser(pydantic_object=MedicalTimeline)\n",
    "\n",
    "# Extraction Tool (LLM)\n",
    "extractor_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a clinical data specialist. Extract a structured timeline from the medical text.\n",
    "Focus on capturing every date and clinical event accurately.\n",
    "\n",
    "Format Instructions:\n",
    "{format_instructions}\n",
    "\n",
    "Medical Text:\n",
    "{text}\n",
    "\"\"\")\n",
    "\n",
    "extractor_tool = extractor_prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
    "\n",
    "# Sorting Tool (Python Logic)\n",
    "def sort_events_tool(events_data):\n",
    "    \"\"\"Sorts JSON events chronologically.\"\"\"\n",
    "    events = events_data.get(\"events\", []) if isinstance(events_data, dict) else events_data\n",
    "    \n",
    "    def parse_date(d):\n",
    "        if not d or d == \"Unknown\": return datetime.max\n",
    "        try: return datetime.strptime(d, \"%Y-%m-%d\")\n",
    "        except: return datetime.max\n",
    "\n",
    "    return sorted(events, key=lambda x: parse_date(x.get('date', 'Unknown')))\n",
    "\n",
    "# 2. Define Supervisor Agent (The Orchestrator)\n",
    "class AdvancedState(TypedDict):\n",
    "    query: str\n",
    "    retrieved_context: str\n",
    "    structured_events: List[dict]\n",
    "    final_report: str\n",
    "\n",
    "def extraction_node(state: AdvancedState):\n",
    "    print(\"--- Supervisor: Extracting Structured Data ---\")\n",
    "    context = state[\"retrieved_context\"]\n",
    "    try:\n",
    "        structured_data = extractor_tool.invoke({\"text\": context})\n",
    "        # Sort immediately using our Python tool\n",
    "        sorted_data = sort_events_tool(structured_data)\n",
    "        return {\"structured_events\": sorted_data}\n",
    "    except Exception as e:\n",
    "        print(f\"Extraction failed: {e}\")\n",
    "        return {\"structured_events\": []}\n",
    "\n",
    "def gap_analysis_node(state: AdvancedState):\n",
    "    print(\"--- Supervisor: Verifying Data Gaps ---\")\n",
    "    events = state[\"structured_events\"]\n",
    "    # Simple logic: Check if we have at least one diagnosis and one outcome/plan\n",
    "    has_diagnosis = any(\"diagnosis\" in e.get(\"event_type\", \"\").lower() for e in events)\n",
    "    if not has_diagnosis:\n",
    "        print(\"Warning: No clear diagnosis found in timeline.\")\n",
    "    return {}\n",
    "\n",
    "def writer_node(state: AdvancedState):\n",
    "    print(\"--- Writer: Generating Final Narrative ---\")\n",
    "    events = state[\"structured_events\"]\n",
    "    \n",
    "    # Convert back to text for the writer LLM\n",
    "    timeline_str = \"\\\\n\".join([f\"{e['date']}: {e['event_type']} - {e['description']} ({e['details']})\" for e in events])\n",
    "    \n",
    "    writer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are a Senior Medical Writer.\n",
    "    Write a comprehensive medical summary based on this verified chronological timeline.\n",
    "    \n",
    "    Timeline:\n",
    "    {timeline}\n",
    "    \n",
    "    Structure:\n",
    "    1. Patient History & Admission\n",
    "    2. Clinical Course (Chronological)\n",
    "    3. Key Findings (Labs/Imaging)\n",
    "    4. Discharge/Current Status\n",
    "    \"\"\")\n",
    "    \n",
    "    chain = writer_prompt | llm | StrOutputParser()\n",
    "    report = chain.invoke({\"timeline\": timeline_str})\n",
    "    return {\"final_report\": report}\n",
    "\n",
    "# Build the Advanced Graph\n",
    "adv_workflow = StateGraph(AdvancedState)\n",
    "adv_workflow.add_node(\"extractor\", extraction_node)\n",
    "adv_workflow.add_node(\"gap_analyst\", gap_analysis_node)\n",
    "adv_workflow.add_node(\"writer\", writer_node)\n",
    "\n",
    "adv_workflow.set_entry_point(\"extractor\")\n",
    "adv_workflow.add_edge(\"extractor\", \"gap_analyst\")\n",
    "adv_workflow.add_edge(\"gap_analyst\", \"writer\")\n",
    "adv_workflow.add_edge(\"writer\", END)\n",
    "\n",
    "advanced_app = adv_workflow.compile()\n",
    "print(\"Advanced Supervisor Agent Compiled Successfully.\")\n",
    "\n",
    "# ==========================================\n",
    "#  EXECUTION OF ADVANCED PIPELINE\n",
    "# ==========================================\n",
    "# Note: Ensure 'vectordb' is indexed (run the indexing cell if needed)\n",
    "\n",
    "def run_advanced_pipeline(query_text):\n",
    "    print(f\"Processing Query: {query_text}\")\n",
    "    \n",
    "    # 1. Retrieve Context (using the existing retriever)\n",
    "    # We need to manually call the retriever or use the graph if we integrated it.\n",
    "    # For this demo, we'll assume we have a retriever tool or use the simple one.\n",
    "    \n",
    "    # Let's use the 'retrieval_executor' from Agent 2 if available, or just search.\n",
    "    # Assuming 'retrieval_executor' is defined in previous cells.\n",
    "    \n",
    "    print(\"Retrieving context...\")\n",
    "    try:\n",
    "        # Simple retrieval for the demo\n",
    "        retrieval_res = retrieval_executor.invoke({\"messages\": [(\"user\", query_text)]})\n",
    "        context_text = retrieval_res[\"messages\"][-1].content\n",
    "    except:\n",
    "        context_text = \"Error retrieving context. Please check vector DB.\"\n",
    "\n",
    "    # 2. Run Supervisor\n",
    "    inputs = {\n",
    "        \"query\": query_text,\n",
    "        \"retrieved_context\": context_text,\n",
    "        \"structured_events\": [],\n",
    "        \"final_report\": \"\"\n",
    "    }\n",
    "    \n",
    "    result = advanced_app.invoke(inputs)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL ADVANCED MEDICAL REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(result[\"final_report\"])\n",
    "    return result\n",
    "\n",
    "# Example Usage (Uncomment to run)\n",
    "# run_advanced_pipeline(\"Summarise the patient's condition based on the medical report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content from: /Users/thirumurugan/Documents/Folder/New Volume F/New Volume F/30_P_Project/Google/Data/Aspire_MedRecs.pdf\n",
      "Content extraction complete. Length: 10353 characters.\n",
      "Content extraction complete. Length: 10353 characters.\n"
     ]
    }
   ],
   "source": [
    "# --- Manual Content Extraction for Analysis ---\n",
    "# This cell ensures 'content' is defined for the subsequent analysis cells.\n",
    "\n",
    "target_pdf_path = \"/Users/thirumurugan/Documents/Folder/New Volume F/New Volume F/30_P_Project/Google/Data/Aspire_MedRecs.pdf\"\n",
    "\n",
    "print(f\"Extracting content from: {target_pdf_path}\")\n",
    "\n",
    "try:\n",
    "    # Try using the helper function if it exists\n",
    "    if 'extract_text_and_images_from_pdf' in locals():\n",
    "        content = extract_text_and_images_from_pdf(target_pdf_path)\n",
    "    else:\n",
    "        # Fallback extraction using PyMuPDF directly\n",
    "        import fitz\n",
    "        doc = fitz.open(target_pdf_path)\n",
    "        content = \"\"\n",
    "        for page in doc:\n",
    "            content += page.get_text()\n",
    "            \n",
    "    print(f\"Content extraction complete. Length: {len(content)} characters.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error extracting content: {e}\")\n",
    "    content = \"\" # Ensure variable exists even on error to prevent NameError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying the medical record...\n",
      "\n",
      "--- Identified Record Type ---\n",
      "Radiology Report\n",
      "--- Identified Record Type ---\n",
      "Radiology Report\n"
     ]
    }
   ],
   "source": [
    "# Classify the specific PDF content\n",
    "if 'content' in locals() and content:\n",
    "    print(\"Classifying the medical record...\\n\")\n",
    "    \n",
    "    # Create a specific prompt for document classification\n",
    "    doc_classifier_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Analyze the following medical document text and determine its type.\n",
    "    Possible types: Lab Report, Discharge Summary, Radiology Report, Prescription, Consultation, Operative Report, Progress Note, or Other.\n",
    "    \n",
    "    Document Content (first 5000 chars):\n",
    "    {text}\n",
    "    \n",
    "    Return ONLY the document type.\n",
    "    \"\"\")\n",
    "    \n",
    "    doc_classifier_chain = doc_classifier_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # Use first 5000 chars to ensure we capture the header/intro which usually contains the type\n",
    "    doc_type = doc_classifier_chain.invoke({\"text\": content[:5000]})\n",
    "    \n",
    "    print(f\"--- Identified Record Type ---\\n{doc_type}\")\n",
    "else:\n",
    "    print(\"Content not found. Please run the extraction cell above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating expert opinion on Radiology findings...\n",
      "\n",
      "--- Radiology Expert Opinion ---\n",
      "Here is a professional opinion based on the provided radiology/imaging reports:\n",
      "\n",
      "**1. Key Imaging Findings:**\n",
      "\n",
      "*   **CT Head with and Without Contrast (11/15/2022):**\n",
      "    *   No evidence of intracranial hemorrhage or infarct.\n",
      "    *   No abnormal enhancement with contrast.\n",
      "    *   Paranasal sinuses are clear.\n",
      "*   **CT Neck with Contrast (11/15/2022):**\n",
      "    *   Parotid glands, submandibular glands, and thyroid appear unremarkable.\n",
      "    *   Nasopharynx, oropharynx, hypopharynx, and larynx are unremarkable.\n",
      "    *   Parapharyngeal space, retropharyngeal space, masticator space, and carotid space are unremarkable.\n",
      "    *   Atherosclerotic calcification is present in both carotid bulbs, but no significant carotid artery stenosis is identified.\n",
      "    *   No evidence of cervical adenopathy.\n",
      "    *   **Cervical Spine:** Mild degenerative changes, including loss of disc space at C5-6 and C6-7 with posterior spondylosis. Posterior spondylosis at C5-6 mildly impinges on the cord. Mild foraminal narrowing. Mild posterior spondylosis effaces the anterior subarachnoid space at C6-7.\n",
      "    *   Lung apices and superior mediastinum are unremarkable.\n",
      "*   **Cervical Spine Four Views (01/18/2023):**\n",
      "    *   Multilevel bilateral facet and uncovertebral osteophyte formation, left greater than right, most significant at C4-5 and C5-6.\n",
      "    *   Osteophyte encroachment on the left neural foramina at C2-3, C3-4, and C4-5.\n",
      "    *   Anterolisthesis at the C7-T1 level measuring 3-4 mm.\n",
      "    *   Disc space narrowing with disc desiccation and anterior osteophyte formation at C4-5, C5-6, C6-7, and C7-T1.\n",
      "    *   Mild posterior osteophyte formation at C5-6 and C6-7.\n",
      "    *   No prevertebral soft tissue abnormality.\n",
      "*   **Cervical Spine (02/15/2023):**\n",
      "    *   Straightening of the normal cervical lordotic curvature.\n",
      "    *   Grade I anterolisthesis of C4 over C5 and C7 over T1.\n",
      "    *   Multilevel degenerative disc changes with uncovertebral joint and facet arthropathy.\n",
      "    *   No acute compression fracture.\n",
      "*   **Cervical Spine Series 3 Views (04/13/2023):**\n",
      "    *   Post-operative changes of anterior cervical fusion from C4 to C6 with plate and screws and disc implants.\n",
      "    *   Satisfactory alignment post-operatively.\n",
      "    *   Marked disc narrowing at C6-7.\n",
      "    *   Prominent degenerative facet changes.\n",
      "    *   Disc narrowing at C7-T1 with stable anterolisthesis.\n",
      "*   **MRI of Lumbar Spine (08/09/2023):**\n",
      "    *   Vertebral bodies maintain fairly normal height.\n",
      "    *   Vertebroplasty changes of L1 with slight superior endplate height loss.\n",
      "    *   Generalized disc desiccation changes.\n",
      "    *   Mild disc narrowing from L2-3 to L4-5.\n",
      "    *   Moderate disc narrowing at L5-S1 with Modic Type I changes and vacuum disc phenomenon at L5-S1.\n",
      "    *   No significant periaortic adenopathy; visualized kidneys are unremarkable.\n",
      "    *   **T12-L1:** No significant canal or foraminal narrowing.\n",
      "    *   **L1-2:** Degenerative facet changes, mild left-sided foraminal narrowing.\n",
      "    *   **L2-3:** Disc bulge, facet and ligamentous hypertrophic changes with mild to moderate canal narrowing and moderate left-sided foraminal narrowing.\n",
      "    *   **L3-4:** Minimal spondylolisthesis (couple millimeters), disc bulge, facet and ligamentous hypertrophic changes with moderately severe canal stenosis. Moderate left and mild right foraminal narrowing.\n",
      "    *   **L4-5:** Prominent facet and ligamentous hypertrophic changes with moderately severe canal stenosis. Very minimal spondylolisthesis. Moderate right and left foraminal narrowing.\n",
      "    *   **L5-S1:** Degenerative facet changes. Right paracentral and lateral disc protrusion with severe right-sided foraminal stenosis. Smaller left lateral disc protrusion and moderate left-sided foraminal narrowing. Mild right-sided lateral recess narrowing.\n",
      "\n",
      "**2. Impressions/Conclusions:**\n",
      "\n",
      "*   **CT Head:** Unremarkable.\n",
      "*   **CT Neck:** No soft tissue abnormality in the neck. Significant degenerative changes in the cervical spine are noted, including cord impingement at C5-6 and effacement of the subarachnoid space at C6-7.\n",
      "*   **Cervical Spine Radiographs/CT:** Multilevel degenerative changes are present throughout the cervical spine, including facet and uncovertebral arthropathy, disc space narrowing, osteophyte formation, and anterolisthesis at C7-T1. Post-operative changes from C4-C6 anterior cervical fusion are noted, with satisfactory alignment. Persistent degenerative changes at C6-7 and C7-T1 are present.\n",
      "*   **Lumbar Spine MRI:** Multilevel degenerative changes are present in the lumbar spine, characterized by disc desiccation, narrowing, facet arthropathy, and ligamentous hypertrophy. Significant findings include multilevel canal stenosis (most severe at L3-4 and L4-5) and multilevel foraminal stenosis (most severe at L5-S1 on the right). Vertebroplasty changes are noted at L1.\n",
      "\n",
      "**3. Recommendations Based on These Findings:**\n",
      "\n",
      "*   **Cervical Spine:** The imaging demonstrates significant multilevel degenerative changes and stenosis in the cervical spine, which are consistent with the history of cervical radiculopathy. The post-operative status of the C4-C6 fusion should be monitored clinically. Given the persistent degenerative changes at C6-7 and C7-T1, and the cord impingement noted on the initial CT, further clinical correlation and management by the referring physician are warranted.\n",
      "*   **Lumbar Spine:** The MRI reveals multilevel canal and foraminal stenosis, particularly at L5-S1 on the right, which can be symptomatic and correlate with back pain. Clinical correlation with the patient's symptoms is essential. Depending on the clinical presentation, further management, which may include conservative treatment or referral to a spine specialist for consideration of surgical intervention for the severe foraminal stenosis at L5-S1, may be indicated.\n",
      "*   **Carotid Bulbs:** While atherosclerotic calcification is noted, the absence of significant stenosis on the CT neck suggests this is not currently a critical finding, but it is a component of overall vascular health.\n",
      "\n",
      "This opinion is based solely on the provided imaging reports. A comprehensive clinical assessment by the treating physician is necessary to integrate these findings with the patient's overall medical condition and guide further management.\n",
      "--- Radiology Expert Opinion ---\n",
      "Here is a professional opinion based on the provided radiology/imaging reports:\n",
      "\n",
      "**1. Key Imaging Findings:**\n",
      "\n",
      "*   **CT Head with and Without Contrast (11/15/2022):**\n",
      "    *   No evidence of intracranial hemorrhage or infarct.\n",
      "    *   No abnormal enhancement with contrast.\n",
      "    *   Paranasal sinuses are clear.\n",
      "*   **CT Neck with Contrast (11/15/2022):**\n",
      "    *   Parotid glands, submandibular glands, and thyroid appear unremarkable.\n",
      "    *   Nasopharynx, oropharynx, hypopharynx, and larynx are unremarkable.\n",
      "    *   Parapharyngeal space, retropharyngeal space, masticator space, and carotid space are unremarkable.\n",
      "    *   Atherosclerotic calcification is present in both carotid bulbs, but no significant carotid artery stenosis is identified.\n",
      "    *   No evidence of cervical adenopathy.\n",
      "    *   **Cervical Spine:** Mild degenerative changes, including loss of disc space at C5-6 and C6-7 with posterior spondylosis. Posterior spondylosis at C5-6 mildly impinges on the cord. Mild foraminal narrowing. Mild posterior spondylosis effaces the anterior subarachnoid space at C6-7.\n",
      "    *   Lung apices and superior mediastinum are unremarkable.\n",
      "*   **Cervical Spine Four Views (01/18/2023):**\n",
      "    *   Multilevel bilateral facet and uncovertebral osteophyte formation, left greater than right, most significant at C4-5 and C5-6.\n",
      "    *   Osteophyte encroachment on the left neural foramina at C2-3, C3-4, and C4-5.\n",
      "    *   Anterolisthesis at the C7-T1 level measuring 3-4 mm.\n",
      "    *   Disc space narrowing with disc desiccation and anterior osteophyte formation at C4-5, C5-6, C6-7, and C7-T1.\n",
      "    *   Mild posterior osteophyte formation at C5-6 and C6-7.\n",
      "    *   No prevertebral soft tissue abnormality.\n",
      "*   **Cervical Spine (02/15/2023):**\n",
      "    *   Straightening of the normal cervical lordotic curvature.\n",
      "    *   Grade I anterolisthesis of C4 over C5 and C7 over T1.\n",
      "    *   Multilevel degenerative disc changes with uncovertebral joint and facet arthropathy.\n",
      "    *   No acute compression fracture.\n",
      "*   **Cervical Spine Series 3 Views (04/13/2023):**\n",
      "    *   Post-operative changes of anterior cervical fusion from C4 to C6 with plate and screws and disc implants.\n",
      "    *   Satisfactory alignment post-operatively.\n",
      "    *   Marked disc narrowing at C6-7.\n",
      "    *   Prominent degenerative facet changes.\n",
      "    *   Disc narrowing at C7-T1 with stable anterolisthesis.\n",
      "*   **MRI of Lumbar Spine (08/09/2023):**\n",
      "    *   Vertebral bodies maintain fairly normal height.\n",
      "    *   Vertebroplasty changes of L1 with slight superior endplate height loss.\n",
      "    *   Generalized disc desiccation changes.\n",
      "    *   Mild disc narrowing from L2-3 to L4-5.\n",
      "    *   Moderate disc narrowing at L5-S1 with Modic Type I changes and vacuum disc phenomenon at L5-S1.\n",
      "    *   No significant periaortic adenopathy; visualized kidneys are unremarkable.\n",
      "    *   **T12-L1:** No significant canal or foraminal narrowing.\n",
      "    *   **L1-2:** Degenerative facet changes, mild left-sided foraminal narrowing.\n",
      "    *   **L2-3:** Disc bulge, facet and ligamentous hypertrophic changes with mild to moderate canal narrowing and moderate left-sided foraminal narrowing.\n",
      "    *   **L3-4:** Minimal spondylolisthesis (couple millimeters), disc bulge, facet and ligamentous hypertrophic changes with moderately severe canal stenosis. Moderate left and mild right foraminal narrowing.\n",
      "    *   **L4-5:** Prominent facet and ligamentous hypertrophic changes with moderately severe canal stenosis. Very minimal spondylolisthesis. Moderate right and left foraminal narrowing.\n",
      "    *   **L5-S1:** Degenerative facet changes. Right paracentral and lateral disc protrusion with severe right-sided foraminal stenosis. Smaller left lateral disc protrusion and moderate left-sided foraminal narrowing. Mild right-sided lateral recess narrowing.\n",
      "\n",
      "**2. Impressions/Conclusions:**\n",
      "\n",
      "*   **CT Head:** Unremarkable.\n",
      "*   **CT Neck:** No soft tissue abnormality in the neck. Significant degenerative changes in the cervical spine are noted, including cord impingement at C5-6 and effacement of the subarachnoid space at C6-7.\n",
      "*   **Cervical Spine Radiographs/CT:** Multilevel degenerative changes are present throughout the cervical spine, including facet and uncovertebral arthropathy, disc space narrowing, osteophyte formation, and anterolisthesis at C7-T1. Post-operative changes from C4-C6 anterior cervical fusion are noted, with satisfactory alignment. Persistent degenerative changes at C6-7 and C7-T1 are present.\n",
      "*   **Lumbar Spine MRI:** Multilevel degenerative changes are present in the lumbar spine, characterized by disc desiccation, narrowing, facet arthropathy, and ligamentous hypertrophy. Significant findings include multilevel canal stenosis (most severe at L3-4 and L4-5) and multilevel foraminal stenosis (most severe at L5-S1 on the right). Vertebroplasty changes are noted at L1.\n",
      "\n",
      "**3. Recommendations Based on These Findings:**\n",
      "\n",
      "*   **Cervical Spine:** The imaging demonstrates significant multilevel degenerative changes and stenosis in the cervical spine, which are consistent with the history of cervical radiculopathy. The post-operative status of the C4-C6 fusion should be monitored clinically. Given the persistent degenerative changes at C6-7 and C7-T1, and the cord impingement noted on the initial CT, further clinical correlation and management by the referring physician are warranted.\n",
      "*   **Lumbar Spine:** The MRI reveals multilevel canal and foraminal stenosis, particularly at L5-S1 on the right, which can be symptomatic and correlate with back pain. Clinical correlation with the patient's symptoms is essential. Depending on the clinical presentation, further management, which may include conservative treatment or referral to a spine specialist for consideration of surgical intervention for the severe foraminal stenosis at L5-S1, may be indicated.\n",
      "*   **Carotid Bulbs:** While atherosclerotic calcification is noted, the absence of significant stenosis on the CT neck suggests this is not currently a critical finding, but it is a component of overall vascular health.\n",
      "\n",
      "This opinion is based solely on the provided imaging reports. A comprehensive clinical assessment by the treating physician is necessary to integrate these findings with the patient's overall medical condition and guide further management.\n"
     ]
    }
   ],
   "source": [
    "# Analyze Radiology Report specifically\n",
    "if 'content' in locals() and content:\n",
    "    print(\"Generating expert opinion on Radiology findings...\\n\")\n",
    "    \n",
    "    radiology_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an expert Radiologist. \n",
    "    Review the following medical document content. \n",
    "    Focus ONLY on the Radiology/Imaging sections (X-rays, CT scans, MRI, Ultrasounds, etc.).\n",
    "    \n",
    "    Provide a professional opinion including:\n",
    "    1. Key Imaging Findings\n",
    "    2. Impressions/Conclusions\n",
    "    3. Recommendations based on these findings\n",
    "    \n",
    "    If no radiology or imaging reports are present in the text, clearly state \"No radiology or imaging findings found in this document.\"\n",
    "    \n",
    "    Document Content:\n",
    "    {text}\n",
    "    \"\"\")\n",
    "    \n",
    "    radiology_chain = radiology_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    radiology_opinion = radiology_chain.invoke({\"text\": content})\n",
    "    \n",
    "    print(f\"--- Radiology Expert Opinion ---\\n{radiology_opinion}\")\n",
    "else:\n",
    "    print(\"Content not found. Please run the extraction cell above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prescription based on radiology report...\n",
      "\n",
      "--- Prescription Recommendation ---\n",
      "As a simulated AI Medical Doctor, I have reviewed the provided radiology reports for Dorothy Stjean. Based on these findings, here is a recommended treatment plan.\n",
      "\n",
      "**Important Disclaimer:** This is an AI simulation and does not constitute actual medical advice. It is crucial to consult with a qualified healthcare professional for diagnosis and treatment.\n",
      "\n",
      "---\n",
      "\n",
      "**Patient:** Dorothy Stjean\n",
      "**DOB:** 9/24/1946\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Recommended Medications\n",
      "\n",
      "**A. For Cervical Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **Medication:** Nonsteroidal Anti-inflammatory Drug (NSAID)\n",
      "    *   **Name:** Ibuprofen (e.g., Advil, Motrin) or Naproxen (e.g., Aleve)\n",
      "    *   **Dosage:** Ibuprofen 400-600 mg or Naproxen 250-500 mg\n",
      "    *   **Frequency:** Every 6-8 hours as needed for pain and inflammation.\n",
      "    *   **Duration:** Initially for 2-4 weeks, then reassess based on symptom response.\n",
      "\n",
      "*   **Medication:** Acetaminophen (Tylenol)\n",
      "    *   **Dosage:** 500-1000 mg\n",
      "    *   **Frequency:** Every 4-6 hours as needed for pain, can be alternated with NSAIDs if pain is not adequately controlled.\n",
      "    *   **Duration:** As needed for pain.\n",
      "\n",
      "*   **Medication (if significant nerve root irritation/radiculopathy symptoms persist):** Gabapentin or Pregabalin\n",
      "    *   **Name:** Gabapentin (e.g., Neurontin) or Pregabalin (e.g., Lyrica)\n",
      "    *   **Dosage:** Start low (e.g., Gabapentin 300 mg at bedtime) and titrate upwards as tolerated and needed for nerve pain. Typical maintenance doses can range from 900-1800 mg/day for Gabapentin, divided into 3 doses. For Pregabalin, start at 75 mg twice daily and titrate up to 150 mg twice daily or higher as needed.\n",
      "    *   **Frequency:** Typically 2-3 times per day.\n",
      "    *   **Duration:** Long-term management may be required, depending on symptom persistence.\n",
      "\n",
      "**B. For Lumbar Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **Medication:** Nonsteroidal Anti-inflammatory Drug (NSAID)\n",
      "    *   **Name:** Ibuprofen (e.g., Advil, Motrin) or Naproxen (e.g., Aleve)\n",
      "    *   **Dosage:** Ibuprofen 400-600 mg or Naproxen 250-500 mg\n",
      "    *   **Frequency:** Every 6-8 hours as needed for pain and inflammation.\n",
      "    *   **Duration:** Initially for 2-4 weeks, then reassess based on symptom response.\n",
      "\n",
      "*   **Medication:** Acetaminophen (Tylenol)\n",
      "    *   **Dosage:** 500-1000 mg\n",
      "    *   **Frequency:** Every 4-6 hours as needed for pain, can be alternated with NSAIDs if pain is not adequately controlled.\n",
      "    *   **Duration:** As needed for pain.\n",
      "\n",
      "*   **Medication (if significant nerve root irritation/radiculopathy symptoms persist in the lumbar spine):** Gabapentin or Pregabalin\n",
      "    *   **Name:** Gabapentin (e.g., Neurontin) or Pregabalin (e.g., Lyrica)\n",
      "    *   **Dosage:** Start low (e.g., Gabapentin 300 mg at bedtime) and titrate upwards as tolerated and needed for nerve pain. Typical maintenance doses can range from 900-1800 mg/day for Gabapentin, divided into 3 doses. For Pregabalin, start at 75 mg twice daily and titrate up to 150 mg twice daily or higher as needed.\n",
      "    *   **Frequency:** Typically 2-3 times per day.\n",
      "    *   **Duration:** Long-term management may be required, depending on symptom persistence.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Reasoning for Each Medication Based on Radiology Results\n",
      "\n",
      "**A. For Cervical Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **NSAIDs (Ibuprofen/Naproxen):**\n",
      "    *   **Reasoning:** The CT Neck with Contrast (11/15/2022) and subsequent Cervical Spine X-rays (01/18/2023, 02/15/2023, 04/13/2023) reveal significant degenerative changes in the cervical spine. These include loss of disc space at C5-6 and C6-7, posterior spondylosis (bone spurs) at C5-6 and C6-7, mild foraminal narrowing, and multilevel bilateral facet and uncovertebral osteophyte formation. The cervical spine series on 01/18/2023 also noted osteophyte encroachment on the left neural foramina at C2-3, C3-4, and C4-5. These findings are consistent with osteoarthritis and can lead to inflammation and pain. NSAIDs are effective in reducing inflammation and alleviating pain associated with these degenerative processes.\n",
      "\n",
      "*   **Acetaminophen (Tylenol):**\n",
      "    *   **Reasoning:** Acetaminophen is a pain reliever that can be used as an adjunct to NSAIDs or as an alternative for patients who cannot tolerate NSAIDs. It addresses the pain component of the degenerative changes.\n",
      "\n",
      "*   **Gabapentin/Pregabalin:**\n",
      "    *   **Reasoning:** The reports indicate \"mild foraminal narrowing\" and \"osteophyte encroachment on the left neural foramina\" in the cervical spine. These findings can compress nerve roots, leading to radiculopathy (nerve pain radiating down the arm). Gabapentin and Pregabalin are anticonvulsant medications that are highly effective in treating neuropathic pain, which is often associated with nerve compression from degenerative spinal conditions.\n",
      "\n",
      "**B. For Lumbar Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **NSAIDs (Ibuprofen/Naproxen):**\n",
      "    *   **Reasoning:** The MRI Lumbar Spine (8/9/2023) shows multilevel degenerative changes, including generalized disc desiccation, mild to moderate disc narrowing from L2-3 to L5-S1, degenerative facet changes, and ligamentous hypertrophy. These changes can cause inflammation and pain in the lower back. NSAIDs are indicated to reduce this inflammation and pain.\n",
      "\n",
      "*   **Acetaminophen (Tylenol):**\n",
      "    *   **Reasoning:** Similar to the cervical spine, acetaminophen provides pain relief for the lumbar degenerative changes and can be used in conjunction with or as an alternative to NSAIDs.\n",
      "\n",
      "*   **Gabapentin/Pregabalin:**\n",
      "    *   **Reasoning:** The lumbar MRI report highlights significant findings that can lead to nerve root compression and radiculopathy:\n",
      "        *   **L2-3:** Mild to moderate canal narrowing and moderate left-sided foraminal narrowing.\n",
      "        *   **L3-4:** Moderately severe canal stenosis and moderate left and mild right foraminal narrowing.\n",
      "        *   **L4-5:** Moderately severe canal stenosis and moderate right and left foraminal narrowing.\n",
      "        *   **L5-S1:** Severe right-sided foraminal stenosis due to disc protrusion and facet changes, with moderate left-sided foraminal narrowing.\n",
      "    These findings strongly suggest nerve root irritation or compression, which can cause back pain and potentially radiating symptoms (though the history states \"back pain without radiculopathy,\" these findings warrant consideration for neuropathic pain management if symptoms develop or are subtle). Gabapentin and Pregabalin are indicated for managing this type of nerve-related pain.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Additional Care Instructions\n",
      "\n",
      "*   **Physical Therapy:** This is a crucial component of managing degenerative spinal conditions. A referral to physical therapy should be made for:\n",
      "    *   **Cervical Spine:** Exercises to strengthen neck muscles, improve posture, and increase range of motion.\n",
      "    *   **Lumbar Spine:** Exercises to strengthen core muscles (abdominal and back muscles), improve flexibility, and promote proper body mechanics.\n",
      "    *   **Education:** Instruction on proper lifting techniques, sitting posture, and sleeping positions to minimize strain on the spine.\n",
      "\n",
      "*   **Activity Modification:** Advise the patient to avoid activities that exacerbate her pain, such as heavy lifting, prolonged sitting or standing in one position, and high-impact activities. Encourage regular movement and stretching.\n",
      "\n",
      "*   **Weight Management:** If the patient is overweight, encourage gradual weight loss, as excess weight puts additional stress on the spine.\n",
      "\n",
      "*   **Heat/Cold Therapy:** Application of heat or cold packs to the affected areas can provide temporary pain relief.\n",
      "\n",
      "*   **Regular Follow-up:** Schedule follow-up appointments to monitor symptom response to medication and physical therapy. Adjust treatment plan as needed.\n",
      "\n",
      "*   **Surgical Consultation:** Given the significant degenerative changes and stenosis in both the cervical and lumbar spine, particularly the severe right-sided foraminal stenosis at L5-S1, a referral to a spine surgeon may be warranted if conservative management fails to provide adequate relief or if neurological deficits develop. The prior anterior cervical fusion (C4-C6) indicates a history of surgical intervention, and further surgical options should be discussed with a specialist.\n",
      "\n",
      "*   **Education on Medication\n",
      "--- Prescription Recommendation ---\n",
      "As a simulated AI Medical Doctor, I have reviewed the provided radiology reports for Dorothy Stjean. Based on these findings, here is a recommended treatment plan.\n",
      "\n",
      "**Important Disclaimer:** This is an AI simulation and does not constitute actual medical advice. It is crucial to consult with a qualified healthcare professional for diagnosis and treatment.\n",
      "\n",
      "---\n",
      "\n",
      "**Patient:** Dorothy Stjean\n",
      "**DOB:** 9/24/1946\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Recommended Medications\n",
      "\n",
      "**A. For Cervical Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **Medication:** Nonsteroidal Anti-inflammatory Drug (NSAID)\n",
      "    *   **Name:** Ibuprofen (e.g., Advil, Motrin) or Naproxen (e.g., Aleve)\n",
      "    *   **Dosage:** Ibuprofen 400-600 mg or Naproxen 250-500 mg\n",
      "    *   **Frequency:** Every 6-8 hours as needed for pain and inflammation.\n",
      "    *   **Duration:** Initially for 2-4 weeks, then reassess based on symptom response.\n",
      "\n",
      "*   **Medication:** Acetaminophen (Tylenol)\n",
      "    *   **Dosage:** 500-1000 mg\n",
      "    *   **Frequency:** Every 4-6 hours as needed for pain, can be alternated with NSAIDs if pain is not adequately controlled.\n",
      "    *   **Duration:** As needed for pain.\n",
      "\n",
      "*   **Medication (if significant nerve root irritation/radiculopathy symptoms persist):** Gabapentin or Pregabalin\n",
      "    *   **Name:** Gabapentin (e.g., Neurontin) or Pregabalin (e.g., Lyrica)\n",
      "    *   **Dosage:** Start low (e.g., Gabapentin 300 mg at bedtime) and titrate upwards as tolerated and needed for nerve pain. Typical maintenance doses can range from 900-1800 mg/day for Gabapentin, divided into 3 doses. For Pregabalin, start at 75 mg twice daily and titrate up to 150 mg twice daily or higher as needed.\n",
      "    *   **Frequency:** Typically 2-3 times per day.\n",
      "    *   **Duration:** Long-term management may be required, depending on symptom persistence.\n",
      "\n",
      "**B. For Lumbar Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **Medication:** Nonsteroidal Anti-inflammatory Drug (NSAID)\n",
      "    *   **Name:** Ibuprofen (e.g., Advil, Motrin) or Naproxen (e.g., Aleve)\n",
      "    *   **Dosage:** Ibuprofen 400-600 mg or Naproxen 250-500 mg\n",
      "    *   **Frequency:** Every 6-8 hours as needed for pain and inflammation.\n",
      "    *   **Duration:** Initially for 2-4 weeks, then reassess based on symptom response.\n",
      "\n",
      "*   **Medication:** Acetaminophen (Tylenol)\n",
      "    *   **Dosage:** 500-1000 mg\n",
      "    *   **Frequency:** Every 4-6 hours as needed for pain, can be alternated with NSAIDs if pain is not adequately controlled.\n",
      "    *   **Duration:** As needed for pain.\n",
      "\n",
      "*   **Medication (if significant nerve root irritation/radiculopathy symptoms persist in the lumbar spine):** Gabapentin or Pregabalin\n",
      "    *   **Name:** Gabapentin (e.g., Neurontin) or Pregabalin (e.g., Lyrica)\n",
      "    *   **Dosage:** Start low (e.g., Gabapentin 300 mg at bedtime) and titrate upwards as tolerated and needed for nerve pain. Typical maintenance doses can range from 900-1800 mg/day for Gabapentin, divided into 3 doses. For Pregabalin, start at 75 mg twice daily and titrate up to 150 mg twice daily or higher as needed.\n",
      "    *   **Frequency:** Typically 2-3 times per day.\n",
      "    *   **Duration:** Long-term management may be required, depending on symptom persistence.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Reasoning for Each Medication Based on Radiology Results\n",
      "\n",
      "**A. For Cervical Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **NSAIDs (Ibuprofen/Naproxen):**\n",
      "    *   **Reasoning:** The CT Neck with Contrast (11/15/2022) and subsequent Cervical Spine X-rays (01/18/2023, 02/15/2023, 04/13/2023) reveal significant degenerative changes in the cervical spine. These include loss of disc space at C5-6 and C6-7, posterior spondylosis (bone spurs) at C5-6 and C6-7, mild foraminal narrowing, and multilevel bilateral facet and uncovertebral osteophyte formation. The cervical spine series on 01/18/2023 also noted osteophyte encroachment on the left neural foramina at C2-3, C3-4, and C4-5. These findings are consistent with osteoarthritis and can lead to inflammation and pain. NSAIDs are effective in reducing inflammation and alleviating pain associated with these degenerative processes.\n",
      "\n",
      "*   **Acetaminophen (Tylenol):**\n",
      "    *   **Reasoning:** Acetaminophen is a pain reliever that can be used as an adjunct to NSAIDs or as an alternative for patients who cannot tolerate NSAIDs. It addresses the pain component of the degenerative changes.\n",
      "\n",
      "*   **Gabapentin/Pregabalin:**\n",
      "    *   **Reasoning:** The reports indicate \"mild foraminal narrowing\" and \"osteophyte encroachment on the left neural foramina\" in the cervical spine. These findings can compress nerve roots, leading to radiculopathy (nerve pain radiating down the arm). Gabapentin and Pregabalin are anticonvulsant medications that are highly effective in treating neuropathic pain, which is often associated with nerve compression from degenerative spinal conditions.\n",
      "\n",
      "**B. For Lumbar Spine Degenerative Changes and Pain:**\n",
      "\n",
      "*   **NSAIDs (Ibuprofen/Naproxen):**\n",
      "    *   **Reasoning:** The MRI Lumbar Spine (8/9/2023) shows multilevel degenerative changes, including generalized disc desiccation, mild to moderate disc narrowing from L2-3 to L5-S1, degenerative facet changes, and ligamentous hypertrophy. These changes can cause inflammation and pain in the lower back. NSAIDs are indicated to reduce this inflammation and pain.\n",
      "\n",
      "*   **Acetaminophen (Tylenol):**\n",
      "    *   **Reasoning:** Similar to the cervical spine, acetaminophen provides pain relief for the lumbar degenerative changes and can be used in conjunction with or as an alternative to NSAIDs.\n",
      "\n",
      "*   **Gabapentin/Pregabalin:**\n",
      "    *   **Reasoning:** The lumbar MRI report highlights significant findings that can lead to nerve root compression and radiculopathy:\n",
      "        *   **L2-3:** Mild to moderate canal narrowing and moderate left-sided foraminal narrowing.\n",
      "        *   **L3-4:** Moderately severe canal stenosis and moderate left and mild right foraminal narrowing.\n",
      "        *   **L4-5:** Moderately severe canal stenosis and moderate right and left foraminal narrowing.\n",
      "        *   **L5-S1:** Severe right-sided foraminal stenosis due to disc protrusion and facet changes, with moderate left-sided foraminal narrowing.\n",
      "    These findings strongly suggest nerve root irritation or compression, which can cause back pain and potentially radiating symptoms (though the history states \"back pain without radiculopathy,\" these findings warrant consideration for neuropathic pain management if symptoms develop or are subtle). Gabapentin and Pregabalin are indicated for managing this type of nerve-related pain.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Additional Care Instructions\n",
      "\n",
      "*   **Physical Therapy:** This is a crucial component of managing degenerative spinal conditions. A referral to physical therapy should be made for:\n",
      "    *   **Cervical Spine:** Exercises to strengthen neck muscles, improve posture, and increase range of motion.\n",
      "    *   **Lumbar Spine:** Exercises to strengthen core muscles (abdominal and back muscles), improve flexibility, and promote proper body mechanics.\n",
      "    *   **Education:** Instruction on proper lifting techniques, sitting posture, and sleeping positions to minimize strain on the spine.\n",
      "\n",
      "*   **Activity Modification:** Advise the patient to avoid activities that exacerbate her pain, such as heavy lifting, prolonged sitting or standing in one position, and high-impact activities. Encourage regular movement and stretching.\n",
      "\n",
      "*   **Weight Management:** If the patient is overweight, encourage gradual weight loss, as excess weight puts additional stress on the spine.\n",
      "\n",
      "*   **Heat/Cold Therapy:** Application of heat or cold packs to the affected areas can provide temporary pain relief.\n",
      "\n",
      "*   **Regular Follow-up:** Schedule follow-up appointments to monitor symptom response to medication and physical therapy. Adjust treatment plan as needed.\n",
      "\n",
      "*   **Surgical Consultation:** Given the significant degenerative changes and stenosis in both the cervical and lumbar spine, particularly the severe right-sided foraminal stenosis at L5-S1, a referral to a spine surgeon may be warranted if conservative management fails to provide adequate relief or if neurological deficits develop. The prior anterior cervical fusion (C4-C6) indicates a history of surgical intervention, and further surgical options should be discussed with a specialist.\n",
      "\n",
      "*   **Education on Medication\n"
     ]
    }
   ],
   "source": [
    "# Generate Prescription based on Radiology Report\n",
    "if 'content' in locals() and content:\n",
    "    print(\"Generating prescription based on radiology report...\\n\")\n",
    "    \n",
    "    prescription_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are a Medical Doctor.\n",
    "    Based on the radiology findings and medical context provided below, prescribe appropriate medication and treatment.\n",
    "    \n",
    "    Please provide:\n",
    "    1. Recommended Medications (Name, Dosage, Frequency, Duration)\n",
    "    2. Reasoning for each medication based on the radiology results\n",
    "    3. Additional care instructions\n",
    "    \n",
    "    DISCLAIMER: This is an AI simulation. Consult a real doctor for actual medical advice.\n",
    "    \n",
    "    Medical Document:\n",
    "    {text}\n",
    "    \"\"\")\n",
    "    \n",
    "    prescription_chain = prescription_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    prescription = prescription_chain.invoke({\"text\": content})\n",
    "    \n",
    "    print(f\"--- Prescription Recommendation ---\\n{prescription}\")\n",
    "else:\n",
    "    print(\"Content not found. Please run the extraction cell above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating structured radiology entry...\n",
      "\n",
      "11/15/2022\tDiagnostic Imaging Huntsville\n",
      "\n",
      "    Andrew Whitmire, MD\tCT HEAD WITH AND WITHOUT CONTRAST:\n",
      "    INDICATIONS:\n",
      "    Headaches, Status post MVA 08/14/2022.\n",
      "    FINDINGS:\n",
      "    CT head without contrast shows no evidence of intracranial hemorrhage or infarct.\n",
      "    CT head with contrast shows no abnormal enhancement,\n",
      "    Paranasal sinuses are clear.\n",
      "    IMPRESSION:\n",
      "    Unremarkable CT head with and without contrast.\n",
      "    CT NECK WITH CONTRAST:\n",
      "    INDICATIONS:\n",
      "    Neck pain,\n",
      "    FINDINGS:\n",
      "    Soft tissue CT of the neck was performed with IV contrast.\n",
      "    Parotid glands, submandibular glands, and thyroid appear unremarkable.\n",
      "    The nasopharynx unremarkable. Oropharynx and hypopharynx unremarkable. Larynx unremarkable.\n",
      "    Parapharyngeal space, retropharyngeal space, masticator space, carotid space unremarkable. There is\n",
      "    atherosclerotic calcification in both carotid bulbs; however, no evidence of significant carotid artery\n",
      "    stenosis identified on this study.\n",
      "    No evidence of cervical adenopathy.\n",
      "    Cervical spine shows mild degenerative change. Loss of disc space at C5-6 and C6-7 with posterior\n",
      "    spondylosis. Posterior spondylosis at C5-6 mildly impinges on the cord. Mild foraminal narrowing,\n",
      "    Mild posterior spondylosis effaces the anterior subarachnoid space at C6-7.\n",
      "    Lung apices and superior mediastinum unremarkable.\n",
      "    IMPRESSION:\n",
      "    1. No soft tissue abnormality in the neck.\n",
      "    2. Degenerative changes in the cervical spine as described.\t1-2\n",
      "11/15/2022\tDiagnostic Imaging Huntsville\n",
      "\n",
      "    Andrew Whitmire, MD\tCT HEAD WITH AND WITHOUT CONTRAST:\n",
      "    INDICATIONS:\n",
      "    Headaches, Status post MVA 08/14/2022.\n",
      "    FINDINGS:\n",
      "    CT head without contrast shows no evidence of intracranial hemorrhage or infarct.\n",
      "    CT head with contrast shows no abnormal enhancement,\n",
      "    Paranasal sinuses are clear.\n",
      "    IMPRESSION:\n",
      "    Unremarkable CT head with and without contrast.\n",
      "    CT NECK WITH CONTRAST:\n",
      "    INDICATIONS:\n",
      "    Neck pain,\n",
      "    FINDINGS:\n",
      "    Soft tissue CT of the neck was performed with IV contrast.\n",
      "    Parotid glands, submandibular glands, and thyroid appear unremarkable.\n",
      "    The nasopharynx unremarkable. Oropharynx and hypopharynx unremarkable. Larynx unremarkable.\n",
      "    Parapharyngeal space, retropharyngeal space, masticator space, carotid space unremarkable. There is\n",
      "    atherosclerotic calcification in both carotid bulbs; however, no evidence of significant carotid artery\n",
      "    stenosis identified on this study.\n",
      "    No evidence of cervical adenopathy.\n",
      "    Cervical spine shows mild degenerative change. Loss of disc space at C5-6 and C6-7 with posterior\n",
      "    spondylosis. Posterior spondylosis at C5-6 mildly impinges on the cord. Mild foraminal narrowing,\n",
      "    Mild posterior spondylosis effaces the anterior subarachnoid space at C6-7.\n",
      "    Lung apices and superior mediastinum unremarkable.\n",
      "    IMPRESSION:\n",
      "    1. No soft tissue abnormality in the neck.\n",
      "    2. Degenerative changes in the cervical spine as described.\t1-2\n"
     ]
    }
   ],
   "source": [
    "# Generate chrono-style row from Radiology Report\n",
    "if 'content' in locals() and content:\n",
    "    print(\"Generating structured radiology entry...\\n\")\n",
    "    \n",
    "    radiology_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are a medico-legal summarizer.\n",
    "    From the following radiology report, create a single-row table (header + one row) with 4 columns:\n",
    "\n",
    "    DATE    FACILITY / PROVIDER    MEDICAL EVENTS    PDF REF\n",
    "\n",
    "    STRICT OUTPUT FORMAT:\n",
    "    - Output exactly 2 lines.\n",
    "    - Line 1 (header) must be:\n",
    "      DATE\\tFACILITY / PROVIDER\\tMEDICAL EVENTS\\tPDF REF\n",
    "    - Line 2 must contain the values for each column, separated by a single tab character.\n",
    "\n",
    "    HOW TO FILL EACH COLUMN:\n",
    "    - DATE:\n",
    "        * Use the study / report date from the document.\n",
    "        * Format it as MM/DD/YYYY (e.g., 03/23/2021).\n",
    "    - FACILITY / PROVIDER:\n",
    "        * On the same column, first write the facility name.\n",
    "        * On the next line(s), write the reporting doctor name.\n",
    "        * Example format:\n",
    "          Aspire Hospital\n",
    "\n",
    "          Ronald Eikenhorst, M.D.\n",
    "    - MEDICAL EVENTS:\n",
    "        * Start with the study/modality name (e.g., \"CT of the brain without contrast:\").\n",
    "        * Then include clearly labeled sections, each on its own line:\n",
    "          \"History:\", \"Findings:\", \"Impression:\", and the recommendation if present.\n",
    "        * Keep wording as close to the original report as possible.\n",
    "        * Do NOT invent findings or add clinical opinions beyond the text.\n",
    "    - PDF REF:\n",
    "        * Use the page reference passed in as {pdf_ref} (for example \"1-2\").\n",
    "\n",
    "    Example of the final structure (for understanding only, not to be copied literally):\n",
    "    DATE\\tFACILITY / PROVIDER\\tMEDICAL EVENTS\\tPDF REF\n",
    "    03/23/2021\\tAspire Hospital\n",
    "\n",
    "    Ronald Eikenhorst, M.D.\\tCT of the brain without contrast:\n",
    "    History: ...\n",
    "    Findings: ...\n",
    "    Impression: ...\n",
    "    Recommendation: ...\\t1-2\n",
    "\n",
    "    Now create the 2-line output for the report below.\n",
    "\n",
    "    Radiology Report:\n",
    "    {text}\n",
    "    \"\"\")\n",
    "\n",
    "    # Chain: prompt -> LLM -> string\n",
    "    radiology_chain = radiology_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # Pass your PDF page reference here (change \"1-2\" as needed per file)\n",
    "    chrono_row = radiology_chain.invoke({\n",
    "        \"text\": content,\n",
    "        \"pdf_ref\": \"1-2\"\n",
    "    })\n",
    "    \n",
    "    print(chrono_row)\n",
    "\n",
    "else:\n",
    "    print(\"Content not found. Please run the extraction cell above first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating structured radiology entries...\n",
      "\n",
      "Report 1: added to DOCX table.\n",
      "\n",
      "Saved chronology table to: radiology_chronology1.docx\n",
      "Report 1: added to DOCX table.\n",
      "\n",
      "Saved chronology table to: radiology_chronology1.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "\n",
    "# ---- 1. Define the prompt & chain (once) ----\n",
    "radiology_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a medico-legal summarizer.\n",
    "From the following radiology report, extract the following fields and return them as a JSON object.\n",
    "\n",
    "Fields:\n",
    "1. \"date\": The study/report date (MM/DD/YYYY).\n",
    "2. \"facility_provider\": The facility name and reporting doctor.\n",
    "3. \"medical_events\": The study name, history, findings, impression, and recommendations. Keep the text structured but use newlines (\\\\n) to separate sections.\n",
    "4. \"pdf_ref\": Use the provided reference: {pdf_ref}\n",
    "\n",
    "JSON Output Format:\n",
    "{{\n",
    "    \"date\": \"...\",\n",
    "    \"facility_provider\": \"...\",\n",
    "    \"medical_events\": \"...\",\n",
    "    \"pdf_ref\": \"...\"\n",
    "}}\n",
    "\n",
    "Radiology Report:\n",
    "{text}\n",
    "\"\"\")\n",
    "\n",
    "# Use JsonOutputParser for robust parsing\n",
    "radiology_chain = radiology_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# ---- 2. Prepare your list of reports ----\n",
    "# If you already have multiple texts, build this list accordingly\n",
    "# Example with a single existing `content`:\n",
    "reports = [\n",
    "    {\"text\": content, \"pdf_ref\": \"1-2\"}\n",
    "]\n",
    "\n",
    "# ---- 3. Create DOCX & header row ----\n",
    "doc = Document()\n",
    "table = doc.add_table(rows=1, cols=4)\n",
    "table.style = 'Table Grid' # Add grid lines for better visibility\n",
    "\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = \"DATE\"\n",
    "hdr_cells[1].text = \"FACILITY / PROVIDER\"\n",
    "hdr_cells[2].text = \"MEDICAL EVENTS\"\n",
    "hdr_cells[3].text = \"PDF REF\"\n",
    "\n",
    "print(\"Generating structured radiology entries...\\n\")\n",
    "\n",
    "# ---- 4. Loop over all reports, call LLM, and fill table ----\n",
    "for idx, report in enumerate(reports, start=1):\n",
    "    text = report[\"text\"]\n",
    "    pdf_ref = report.get(\"pdf_ref\", \"\")\n",
    "\n",
    "    if not text or not text.strip():\n",
    "        print(f\"Report {idx}: empty text, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        data = radiology_chain.invoke({\n",
    "            \"text\": text,\n",
    "            \"pdf_ref\": pdf_ref\n",
    "        })\n",
    "        \n",
    "        # Add row to DOCX table\n",
    "        row_cells = table.add_row().cells\n",
    "        row_cells[0].text = data.get(\"date\", \"\")\n",
    "        row_cells[1].text = data.get(\"facility_provider\", \"\")\n",
    "        row_cells[2].text = data.get(\"medical_events\", \"\")\n",
    "        row_cells[3].text = data.get(\"pdf_ref\", \"\")\n",
    "\n",
    "        print(f\"Report {idx}: added to DOCX table.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Report {idx}: failed to process. Error: {e}\")\n",
    "\n",
    "# ---- 5. Save DOCX ----\n",
    "output_path = \"radiology_chronology1.docx\"\n",
    "doc.save(output_path)\n",
    "print(f\"\\nSaved chronology table to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating structured medical entries...\n",
      "\n",
      "Report 1 (Radiology Report): added to DOCX table.\n",
      "\n",
      "Saved chronology table to: medical_chronology.docx\n",
      "Report 1 (Radiology Report): added to DOCX table.\n",
      "\n",
      "Saved chronology table to: medical_chronology.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "\n",
    "# ---- 1. Define the prompt & chain (generic for ANY medical record) ----\n",
    "medical_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a medico-legal summarizer.\n",
    "You will be given a {record_type} from a patient's medical record.\n",
    "\n",
    "From the following medical record text, extract the following fields and return them as a JSON object.\n",
    "\n",
    "Fields:\n",
    "1. \"date\": The service / visit / study / report date in MM/DD/YYYY format (if multiple dates, choose the main date of service/report).\n",
    "2. \"facility_provider\": The facility/clinic/hospital name and the main provider (doctor, NP, PA, therapist, etc.).\n",
    "   - Combine them into a single string, with provider on a new line if helpful.\n",
    "3. \"medical_events\": A concise but complete medico-legal summary of what happened in this record.\n",
    "   - Include, as applicable for this record type:\n",
    "     - For radiology: study name, history/indication, key findings, impression, recommendations.\n",
    "     - For office/ER/clinic notes: chief complaint, history, exam findings, diagnoses, treatments, medications.\n",
    "     - For operative reports: procedure name, indications, key intraoperative findings, complications, immediate outcome.\n",
    "     - For discharge summaries: admission reason, hospital course, diagnoses, discharge condition, follow-up plan.\n",
    "   - Keep the text structured but use newlines (\\\\n) to separate logical sections (e.g., \"History:\", \"Findings:\", \"Impression:\", \"Plan:\", etc.).\n",
    "   - Do NOT invent facts that are not supported by the text.\n",
    "4. \"pdf_ref\": Use exactly the provided reference: {pdf_ref}\n",
    "\n",
    "JSON Output Format:\n",
    "{{\n",
    "    \"date\": \"...\",\n",
    "    \"facility_provider\": \"...\",\n",
    "    \"medical_events\": \"...\",\n",
    "    \"pdf_ref\": \"...\"\n",
    "}}\n",
    "\n",
    "Medical Record Text:\n",
    "{text}\n",
    "\"\"\")\n",
    "\n",
    "# Use JsonOutputParser for robust parsing\n",
    "medical_chain = medical_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# ---- 2. Prepare your list of reports (ANY type, not just radiology) ----\n",
    "# Example: you can mix radiology + office visit + discharge summary etc.\n",
    "# Each item must have \"text\" and \"pdf_ref\", and can optionally have \"record_type\"\n",
    "reports = [\n",
    "    {\n",
    "        \"text\": content,              # e.g. Dorothy CT report\n",
    "        \"pdf_ref\": \"1-2\",\n",
    "        \"record_type\": \"Radiology Report\"\n",
    "    },\n",
    "    # {\n",
    "    #     \"text\": clinic_note_text,\n",
    "    #     \"pdf_ref\": \"3-4\",\n",
    "    #     \"record_type\": \"Office Visit Note\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"text\": discharge_summary_text,\n",
    "    #     \"pdf_ref\": \"5-7\",\n",
    "    #     \"record_type\": \"Discharge Summary\"\n",
    "    # },\n",
    "]\n",
    "\n",
    "# ---- 3. Create DOCX & header row ----\n",
    "doc = Document()\n",
    "table = doc.add_table(rows=1, cols=4)\n",
    "table.style = 'Table Grid'  # Add grid lines for better visibility\n",
    "\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = \"DATE\"\n",
    "hdr_cells[1].text = \"FACILITY / PROVIDER\"\n",
    "hdr_cells[2].text = \"MEDICAL EVENTS\"\n",
    "hdr_cells[3].text = \"PDF REF\"\n",
    "\n",
    "print(\"Generating structured medical entries...\\n\")\n",
    "\n",
    "# ---- 4. Loop over all reports, call LLM, and fill table ----\n",
    "for idx, report in enumerate(reports, start=1):\n",
    "    text = report.get(\"text\", \"\")\n",
    "    pdf_ref = report.get(\"pdf_ref\", \"\")\n",
    "    record_type = report.get(\"record_type\", \"medical record\")\n",
    "\n",
    "    if not text or not text.strip():\n",
    "        print(f\"Report {idx}: empty text, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        data = medical_chain.invoke({\n",
    "            \"text\": text,\n",
    "            \"pdf_ref\": pdf_ref,\n",
    "            \"record_type\": record_type\n",
    "        })\n",
    "\n",
    "        # Add row to DOCX table\n",
    "        row_cells = table.add_row().cells\n",
    "        row_cells[0].text = data.get(\"date\", \"\")\n",
    "        row_cells[1].text = data.get(\"facility_provider\", \"\")\n",
    "        row_cells[2].text = data.get(\"medical_events\", \"\")\n",
    "        row_cells[3].text = data.get(\"pdf_ref\", \"\")\n",
    "\n",
    "        print(f\"Report {idx} ({record_type}): added to DOCX table.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Report {idx} ({record_type}): failed to process. Error: {e}\")\n",
    "\n",
    "# ---- 5. Save DOCX ----\n",
    "output_path = \"medical_chronology.docx\"\n",
    "doc.save(output_path)\n",
    "print(f\"\\nSaved chronology table to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
